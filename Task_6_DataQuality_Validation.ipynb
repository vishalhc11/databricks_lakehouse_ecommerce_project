{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1404eb6c-38d1-44ff-aa7c-491a56423952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, expr\n",
    "\n",
    "# Set context\n",
    "spark.sql(\"USE CATALOG main\")\n",
    "spark.sql(\"USE SCHEMA ecommerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a273bc8a-74b5-45b0-a7c3-16f6e1c6accd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Task 6 - Data Quality & Validation\n",
    "\n",
    "Objective:  Ensure correctness and reliability.\n",
    "\n",
    "What You Need to Do \n",
    "- Perform row count checks\n",
    "- Validate nulls in key columns\n",
    "- Perform revenue sanity checks\n",
    "- Fail the pipeline if validations fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062b6c71-d83d-4156-b024-9f529f9e8514",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CHECK 1: ROW COUNT CHECK (Are the tables empty?)\n",
    "# ---------------------------------------------------------\n",
    "tables_to_check = [\"customer\", \"fact_sales\", \"order_items\", \"orders\", \"products\",\"order_payments\"]\n",
    "\n",
    "for table in tables_to_check:\n",
    "    row_count = spark.read.table(table).count()\n",
    "    print(f\"Checking {table}: {row_count} rows found.\")\n",
    "    \n",
    "    if row_count == 0:\n",
    "        raise Exception(f\"CRITICAL ERROR: Table {table} is empty! Pipeline stopped.\")\n",
    "\n",
    "print(\"--> Row Count Checks Passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb6db43-556b-4b63-8e1c-6a04f75c9f5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CHECK 2: NULL CHECK (Do we have Null Primary Keys?)\n",
    "# ---------------------------------------------------------\n",
    "# We check fact_sales for null order_ids\n",
    "null_count = spark.read.table(\"fact_sales\") \\\n",
    "    .filter( (col(\"order_id\").isNull()) & (col(\"order_item_id\").isNull()) ) \\\n",
    "    .count()\n",
    "\n",
    "if null_count > 0:\n",
    "    raise Exception(f\"DATA INTEGRITY ERROR: Found {null_count} null Order IDs in Fact Table!\")\n",
    "\n",
    "print(\"--> Null ID Checks Passed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95767b9c-cbb0-47e1-a888-201b8c4cef9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CHECK 3: BUSINESS LOGIC CHECK (Negative Revenue?)\n",
    "# ---------------------------------------------------------\n",
    "# Revenue cannot be negative. If it is, something is wrong.\n",
    "negative_revenue_count = spark.read.table(\"fact_sales\") \\\n",
    "    .filter(col(\"revenue\") < 0) \\\n",
    "    .count()\n",
    "\n",
    "if negative_revenue_count > 0:\n",
    "    print(f\"WARNING: Found {negative_revenue_count} records with negative revenue.\")\n",
    "    # In some companies, this is a warning. In this assignment, let's be strict:\n",
    "    raise Exception(\"BUSINESS LOGIC ERROR: Negative Revenue found! Pipeline stopped.\")\n",
    "\n",
    "print(\"--> Revenue Sanity Checks Passed.\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"SUCCESS: All Data Quality Checks Passed!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8461962565059783,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Task_6_DataQuality_Validation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
